{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "In this notebook, I'll be going through a very simple classification problem and documenting each step. The goal is to create an example notebook for future classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "Downloading MNIST using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "# set as_frame to False for numpy\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, data_home='./datasets')\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Description\n",
    "# mnist[\"DESCR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating variables for data and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images, each with 784 features. In this case, the features are individual pixels of each image, since each image is 28 x 28 pixels. \n",
    "\n",
    "Let's take a look at a random image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAE8klEQVR4nO3dsW+NbQCHYa1vQYSBUVkNRCJGq8Fg6mgyMJ2/w2T2NwiisRgtImxiYZBYmhwDkZjaRHK+WdI+/b721LnbXtfYX954BnefxJtzLM1ms2NAz/KiDwBsTZwQJU6IEidEiROi/tlh90+5sP+WtvqhmxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCHqn0UfgP9nNpsN9+l0OtyfPn063J89e7bt9uXLl+Gz79+/H+4rKyvDnT+5OSFKnBAlTogSJ0SJE6LECVHihCjvORdgfX19221tbW347JMnT4b7mzdvdnOk/+TUqVPD/eTJk/v2Zx9Fbk6IEidEiROixAlR4oQocUKUOCHKe85d+Pjx43B/+PDhcH/x4sW22+bm5vDZS5cuDffJZDLcf//+PdwfP3687Xbr1q3hs+fOnRvu/D9uTogSJ0SJE6LECVHihChxQpQ4IepIvud8/fr1cL93795w//bt23Df2NgY7vfv3992u3v37vDZ69evD/edPlP54cOH4T56z3nlypXhs8yXmxOixAlR4oQocUKUOCFKnBAlTog6ku85v3//PtyvXbs23Hf6/tbV1dXhfufOnW235eXu78sTJ04s+ghHSvdvAhxx4oQocUKUOCFKnBAlTohams1mo304cvDcvn17uL969Wrb7efPn8Nnz549u5sjcezY0lY/dHNClDghSpwQJU6IEidEiROixAlRR/IjY0fZdDpd9BH4j9ycECVOiBInRIkTosQJUeKEKHFClPec/OHGjRvbbqdPn/6LJ8HNCVHihChxQpQ4IUqcECVOiBInRHnPecisr68P90+fPg330X9PePz48V2did1xc0KUOCFKnBAlTogSJ0SJE6LECVHecx4ya2trw31zc3O4TyaTOZ6GvXBzQpQ4IUqcECVOiBInRIkTorxKOWTevn073JeXx7+PL168OM/jsAduTogSJ0SJE6LECVHihChxQpQ4Icp7zkNmOp0O96tXrw73lZWVeR6HPXBzQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRPs95wPz69Wu4v3v3brjfvHlznsdhH7k5IUqcECVOiBInRIkTosQJUV6lHDAvX74c7hsbG8N9MpnM8zjsIzcnRIkTosQJUeKEKHFClDghSpwQ5T3nAfP8+fM9PX/hwoU5nYT95uaEKHFClDghSpwQJU6IEidEiROivOc8ZM6cOTPcz58//5dOwl65OSFKnBAlTogSJ0SJE6LECVHihKil2Ww22ocjf9/ly5eH+07fW/v169d5Hof5WNrqh25OiBInRIkTosQJUeKEKHFClDghyuc5Yx49ejTcP3/+PNwfPHgwz+OwQG5OiBInRIkTosQJUeKEKHFClFcpMT9+/NjT86urq3M6CYvm5oQocUKUOCFKnBAlTogSJ0SJE6J8NSYsnq/GhINEnBAlTogSJ0SJE6LECVHihKidPs+55fsXYP+5OSFKnBAlTogSJ0SJE6LECVH/An5CixuGdyRAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a digit from array\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[42]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the label is a string, let's convert it to an int so that our algorithm will understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test set and train set\n",
    "We should always split the data into training and testing BEFORE looking into the data. The MNIST dataset is already split (first 60,000 is training, last 10,000 is test) and shuffled, so we just need to index it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier\n",
    "Let's simplify the problem by first training a simple binary classifier that will identify one digit, let's choose 7. It will pick between two classes: 7 and not-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_7 = (y_train == 7)\n",
    "y_test_7 = (y_test == 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our labels will be boolean values, based on whether the given digit is a seven or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_7[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, most values will be False, which is expected.\n",
    "\n",
    "Let's start with training an SGD classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see for this digit that we displayed before, the binary classifier correctly predicted that it was a 7. That's great, but we should develop a better way to evaluate this model and any future classifiers we use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "Evaluating a classifier is a bit trickier than a regressor, we're going to try a few different methods here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "Let's use K-fold cross-validation to evaluate our model. For *n* number of folds, it will evaluate our model *n* times, each time training the model on *n-1* folds and testing it on the remaining one.\n",
    "\n",
    "Let's use scikit-learn's `cross_val_score()` to keep it simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98105, 0.9735 , 0.95335])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_7, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, so it appears that our model has an accuracy above 95%! Before we get too excited, let's compare it to another classifier here that will always guess that the digit is **not** seven:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class NeverSevenClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89535, 0.8984 , 0.893  ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_seven_classifier = NeverSevenClassifier()\n",
    "cross_val_score(never_seven_classifier, X_train, y_train_7, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 90%! Thinking about it, this is totally expected. There are 10 possible digits, so guessing that a given digit will be 7 has 10% odds. \n",
    "\n",
    "Thus, accuracy is generally not the preferred perfomance measure for classifiers, especially for *skewed datasets* (in this case, not-7 is way more likely than 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
